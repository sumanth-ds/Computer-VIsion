{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62cba21d-12be-4760-84ac-94fc67dc8519",
   "metadata": {},
   "source": [
    "# Import Basic Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2586d029-3cd3-416b-9369-c536b95e6b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7446f2a-0134-495a-acf4-119418b8c48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_width_rect = 80\n",
    "min_height_rect = 80\n",
    "offset = 6\n",
    "delay = 60\n",
    "carros = 0\n",
    "count_line_pos = 550\n",
    "detect = []\n",
    "\n",
    "\n",
    "def central_handle(x,y,w,h):\n",
    "    x1 = int(w/2)\n",
    "    y1 = int(h/2)\n",
    "    cx = x+x1\n",
    "    cy = y+y1\n",
    "    return cx, cy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# enable web camera\n",
    "\n",
    "cap = cv2.VideoCapture('video.mp4')\n",
    "#algo = cv2.createBackgroundSubtractorMOG2()\n",
    "algo = cv2.createBackgroundSubtractorKNN()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "while True:\n",
    "    ret, frame1 = cap.read()\n",
    "    gray = cv2.cvtColor(frame1 , cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray, (3,3), 5)\n",
    "    # Applying preprocessing on Each frame\n",
    "    img_sub = algo.apply(blur)\n",
    "    dilat = cv2.dilate(img_sub, np.ones((5,5)))\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(5,5))\n",
    "    dilatdata = cv2.morphologyEx(dilat, cv2.MORPH_CLOSE, kernel)\n",
    "    dilatdata = cv2.morphologyEx(dilatdata, cv2.MORPH_CLOSE, kernel)\n",
    "    counterShape , h= cv2.findContours(dilatdata, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    cv2.line(frame1 , (25,count_line_pos), (1200, count_line_pos), (0,0,255), 3)\n",
    "    \n",
    "    for (i,c) in enumerate(counterShape):\n",
    "        (x,y,w,h) = cv2.boundingRect(c)\n",
    "        validar_cantorno = (w >= min_width_rect)  and (h >= min_height_rect)\n",
    "    \n",
    "\n",
    "    if not validar_cantorno:\n",
    "        continue\n",
    "    cv2.rectangle(frame1, (x,y), (x+w, y+h), 0,255,0 , 2)\n",
    "    cv2.putText(frame1, 'Vehicle' + str(carros), (x, y-20), cv2.FONT_HERSHEY_TRIPLEX, 1, (255,0, 255), 2)\n",
    "    center = central_handle(x,y,w,h)\n",
    "    detect.append(center)\n",
    "    cv2.circle(frame1, center, 4, (200, 100, 50), -1)\n",
    "\n",
    "    # loop function - checking if the vehicle crossed the line\n",
    "\n",
    "    for (x,y) in detect:\n",
    "        if y< (count_line_pos + offset) and y>(count_line_pos):\n",
    "            corros +=1\n",
    "            cv2.line(frame1, (25,count_line_pos), (1200, count_line_pos), (0,0,25), 3)\n",
    "            print('Car is detecting: ', str(carros))\n",
    "\n",
    "    cv2.putText(frame1, 'Vehicle' + str(carros), (x, y-20), cv2.FONT_HERSHEY_TRIPLEX, 1, (255,0, 255), 2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    cv2.imshow('Original Video', frame1)\n",
    "    if cv2.waitKey(1) == 13:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1b0af0-3c1d-44a7-a275-decde4446ef7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
